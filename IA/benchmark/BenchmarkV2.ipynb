{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7023d858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Ajouter le dossier parent (contenant IA et Database)\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "856969e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RED94\\Desktop\\RAIN\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from Database.db import *\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import seaborn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import emoji\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder,FunctionTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from sklearn.impute import SimpleImputer \n",
    "\n",
    "from sentence_transformers import SentenceTransformer,util\n",
    "import hdbscan\n",
    "from sklearn.metrics import silhouette_score\n",
    "import warnings\n",
    "\n",
    "from bertopic import BERTopic\n",
    "\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba4f7e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Télécharger les listes de mots vides en anglais et français une seule fois\n",
    "try:\n",
    "    stopwords.words('english')\n",
    "except LookupError:\n",
    "    print(\"Téléchargement des listes de stopwords de NLTK...\")\n",
    "    nltk.download('stopwords')\n",
    "    print(\"Téléchargement terminé.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01663698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Rain'\n",
      "'postgres'\n",
      "'Root'\n",
      "'localhost'\n",
      "Connexion réussie : 1\n"
     ]
    }
   ],
   "source": [
    "engine = connect_to_db(\n",
    "    os.environ['DB_NAME'],\n",
    "    os.environ['DB_USER'],\n",
    "    os.environ['DB_PASSWORD'],\n",
    "    os.environ['DB_HOST'],\n",
    "    os.environ['DB_PORT']\n",
    "    )\n",
    "    # Lire la table souhaitée\n",
    "df = pd.read_sql_table(\"githubRepo\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "323dcabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_rare_categories(series, threshold_ratio=0.01, new_category_name='other'):\n",
    "    \"\"\"Regroupe les catégories rares en une seule catégorie 'other'.\"\"\"\n",
    "    series_no_na = series.dropna()\n",
    "    if len(series_no_na) == 0:\n",
    "        return series\n",
    "    counts = series_no_na.value_counts()\n",
    "    threshold_count = len(series) * threshold_ratio\n",
    "    rare_categories = counts[counts < threshold_count].index\n",
    "    return series.replace(rare_categories, new_category_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6310b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Fonctions de Nettoyage par Étape ---\n",
    "\n",
    "def clean_text_features(df):\n",
    "    \"\"\"Étape 1: Nettoie les colonnes textuelles et crée 'cleaned_text'.\"\"\"\n",
    "    print(\"\\n[1/5] Nettoyage du texte...\")\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    # Gestion des valeurs manquantes\n",
    "    df_processed.replace([None, ''], np.nan, inplace=True)\n",
    "    df_processed['topics'] = df_processed['topics'].apply(lambda x: np.nan if (isinstance(x, list) and not x) else x)\n",
    "    df_processed['description_translated'].fillna('', inplace=True)\n",
    "    df_processed['topics'].fillna('', inplace=True)\n",
    "    \n",
    "    # Définition des stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    custom_stop_words = {\n",
    "        'repository', 'explore', 'contribute', 'project', 'github', 'app', 'application', \n",
    "        'tool', 'library', 'framework', 'platform', 'model', 'gui', 'api', 'backend', 'interface'\n",
    "    }\n",
    "    stop_words.update(custom_stop_words)\n",
    "\n",
    "    def clean_text(text):\n",
    "        if not isinstance(text, str): return \"\"\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "        text = re.sub(r'[^\\w\\s-]', '', text)\n",
    "        words = text.split()\n",
    "        cleaned_words = [word for word in words if word not in stop_words and len(word) > 1]\n",
    "        return ' '.join(cleaned_words)\n",
    "\n",
    "    df_processed['cleaned_description'] = df_processed['description_translated'].apply(clean_text)\n",
    "\n",
    "    def clean_topics(topics_data):\n",
    "        if isinstance(topics_data, list): topics_list = [str(t).lower() for t in topics_data]\n",
    "        elif isinstance(topics_data, str): topics_list = topics_data.lower().split()\n",
    "        else: return \"\"\n",
    "        unique_topics = sorted(list(set(topics_list)))\n",
    "        cleaned_topics = [topic for topic in unique_topics if topic not in stop_words and len(topic) > 1]\n",
    "        return ' '.join(cleaned_topics)\n",
    "\n",
    "    df_processed['cleaned_topics'] = df_processed['topics'].apply(clean_topics)\n",
    "    \n",
    "    # Combiner la description et les topics nettoyés\n",
    "    df_processed['cleaned_text'] = df_processed['cleaned_description'] + ' ' + df_processed['cleaned_topics']\n",
    "    \n",
    "    # Supprimer les espaces multiples\n",
    "    df_processed['cleaned_text'] = df_processed['cleaned_text'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "\n",
    "    \n",
    "    return df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bb8cd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_datetime_features(df):\n",
    "    \"\"\"Étape 2: Crée les features basées sur les dates.\"\"\"\n",
    "    print(\"\\n[2/5] Création des features temporelles...\")\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    df_processed['created_at'] = pd.to_datetime(df_processed['created_at'], errors='coerce')\n",
    "    df_processed['updated_at'] = pd.to_datetime(df_processed['updated_at'], errors='coerce')\n",
    "    df_processed.dropna(subset=['created_at'], inplace=True)\n",
    "\n",
    "    df_processed['updated_at'] = df_processed.apply(\n",
    "        lambda row: row['created_at'] if pd.isna(row['updated_at']) or row['updated_at'] < row['created_at'] else row['updated_at'],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    current_time = pd.Timestamp.now()\n",
    "    df_processed['repo_age_days'] = (current_time - df_processed['created_at']).dt.days\n",
    "    df_processed['days_since_last_update'] = (current_time - df_processed['updated_at']).dt.days\n",
    "    df_processed['created_year'] = df_processed['created_at'].dt.year\n",
    "    return df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a77b027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_categorical_features(df):\n",
    "    \"\"\"Étape 3: Nettoie et regroupe les features catégorielles.\"\"\"\n",
    "    print(\"\\n[3/5] Nettoyage des features catégorielles...\")\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    df_processed['license'].fillna('No License', inplace=True)\n",
    "    df_processed['license'] = group_rare_categories(df_processed['license'], new_category_name='other_license')\n",
    "    \n",
    "    if 'langue' in df_processed.columns:\n",
    "        df_processed['langue'].fillna('Unknown', inplace=True)\n",
    "        df_processed['langue'] = group_rare_categories(df_processed['langue'], new_category_name='other_language')\n",
    "        \n",
    "    return df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "108ad78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_numeric_features(df):\n",
    "    \"\"\"Étape 4: Applique une transformation logarithmique aux features numériques.\"\"\"\n",
    "    print(\"\\n[4/5] Transformation des features numériques...\")\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    for col in ['stargazers_count', 'forks_count']:\n",
    "        if col in df_processed.columns:\n",
    "            df_processed[f'{col}_log'] = np.log1p(df_processed[col].astype(float))\n",
    "    \n",
    "    return df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45438c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalize_dataset(df):\n",
    "    \"\"\"Étape 5: Sélectionne les colonnes finales et effectue un dernier nettoyage.\"\"\"\n",
    "    print(\"\\n[5/5] Sélection finale des colonnes...\")\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    final_columns = [\n",
    "        'name', 'description_translated', 'cleaned_text', 'topics', 'license', 'langue',\n",
    "        'stargazers_count', 'forks_count', 'stargazers_count_log', 'forks_count_log',\n",
    "        'repo_age_days', 'days_since_last_update', 'created_year', 'html_url'\n",
    "    ]\n",
    "    \n",
    "    for col in final_columns:\n",
    "        if col not in df_processed.columns:\n",
    "            df_processed[col] = np.nan\n",
    "\n",
    "    df_final = df_processed[final_columns]\n",
    "    df_final = df_final[df_final['cleaned_text'] != ''].copy()\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "494d4c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_full_preparation_pipeline(df_raw):\n",
    "    \"\"\"\n",
    "    Exécute toutes les étapes de nettoyage et de préparation en séquence.\n",
    "    \"\"\"\n",
    "    print(\"--- Début du Pipeline de Préparation Complet ---\")\n",
    "    \n",
    "    df = clean_text_features(df_raw)\n",
    "    df = engineer_datetime_features(df)\n",
    "    df = clean_categorical_features(df)\n",
    "    df = transform_numeric_features(df)\n",
    "    df = finalize_dataset(df)\n",
    "    \n",
    "    print(\"\\n--- Pipeline de Préparation Terminé ---\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a8eb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Début du Pipeline de Préparation Complet ---\n",
      "\n",
      "[1/5] Nettoyage du texte...\n",
      "\n",
      "[2/5] Création des features temporelles...\n",
      "\n",
      "[3/5] Nettoyage des features catégorielles...\n",
      "\n",
      "[4/5] Transformation des features numériques...\n",
      "\n",
      "[5/5] Sélection finale des colonnes...\n",
      "\n",
      "--- Pipeline de Préparation Terminé ---\n",
      "\n",
      "--- Aperçu du DataFrame 'Parfait' ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7191 entries, 0 to 7193\n",
      "Data columns (total 14 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   name                    7191 non-null   object \n",
      " 1   description_translated  7191 non-null   object \n",
      " 2   cleaned_text            7191 non-null   object \n",
      " 3   topics                  7191 non-null   object \n",
      " 4   license                 7191 non-null   object \n",
      " 5   langue                  7191 non-null   object \n",
      " 6   stargazers_count        7191 non-null   int64  \n",
      " 7   forks_count             7191 non-null   int64  \n",
      " 8   stargazers_count_log    7191 non-null   float64\n",
      " 9   forks_count_log         7191 non-null   float64\n",
      " 10  repo_age_days           7191 non-null   int64  \n",
      " 11  days_since_last_update  7191 non-null   int64  \n",
      " 12  created_year            7191 non-null   int32  \n",
      " 13  html_url                7191 non-null   object \n",
      "dtypes: float64(2), int32(1), int64(4), object(7)\n",
      "memory usage: 814.6+ KB\n",
      "None\n",
      "\n",
      "\n",
      "                                    name  \\\n",
      "0                 stable-diffusion-webui   \n",
      "1                               supabase   \n",
      "2                                ComfyUI   \n",
      "3                          Deep-Live-Cam   \n",
      "4  system-prompts-and-models-of-ai-tools   \n",
      "\n",
      "                                                            description_translated  \\\n",
      "0                                                          Stable Diffusion web UI   \n",
      "1  The Postgres development platform. Supabase gives you a dedicated Postgres d...   \n",
      "2  The most powerful and modular diffusion model GUI, api and backend with a gr...   \n",
      "3        real time face swap and one-click video deepfake with only a single image   \n",
      "4  FULL v0, Cursor, Manus, Same.dev, Lovable, Devin, Replit Agent, Windsurf Age...   \n",
      "\n",
      "                                                                      cleaned_text  \\\n",
      "0  stable diffusion web ui ai-art deep-learning diffusion gradio image-generati...   \n",
      "1  postgres development supabase gives dedicated postgres database build web mo...   \n",
      "2            powerful modular diffusion graphnodes python pytorch stable-diffusion   \n",
      "3  real time face swap one-click video deepfake single image ai-deep-fake ai-fa...   \n",
      "4  full v0 cursor manus samedev lovable devin replit agent windsurf agent vscod...   \n",
      "\n",
      "                                                                            topics  \\\n",
      "0  [ai, ai-art, deep-learning, diffusion, gradio, image-generation, image2image...   \n",
      "1  [ai, alternative, auth, database, deno, embeddings, example, firebase, nextj...   \n",
      "2                                          [ai, python, pytorch, stable-diffusion]   \n",
      "3  [ai, ai-deep-fake, ai-face, ai-webcam, artificial-intelligence, deep-fake, d...   \n",
      "4  [ai, bolt, cluely, copilot, cursor, cursorai, devin, devinai, github-copilot...   \n",
      "\n",
      "      license langue  stargazers_count  forks_count  stargazers_count_log  \\\n",
      "0    AGPL-3.0     en            154394        28671             11.947270   \n",
      "1  Apache-2.0     en             85584         9184             11.357265   \n",
      "2     GPL-3.0     en             82202         9102             11.316947   \n",
      "3    AGPL-3.0     en             71709        10275             11.180385   \n",
      "4     GPL-3.0     en             66282        19273             11.101689   \n",
      "\n",
      "   forks_count_log  repo_age_days  days_since_last_update  created_year  \\\n",
      "0        10.263676           1093                      39          2022   \n",
      "1         9.125327           2138                      39          2019   \n",
      "2         9.116359            946                      39          2023   \n",
      "3         9.237566            695                      39          2023   \n",
      "4         9.866512            167                      39          2025   \n",
      "\n",
      "                                                           html_url  \n",
      "0           https://github.com/AUTOMATIC1111/stable-diffusion-webui  \n",
      "1                              https://github.com/supabase/supabase  \n",
      "2                         https://github.com/comfyanonymous/ComfyUI  \n",
      "3                        https://github.com/hacksider/Deep-Live-Cam  \n",
      "4  https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools  \n"
     ]
    }
   ],
   "source": [
    "# Appliquer le pipeline complet\n",
    "df_cleaned = run_full_preparation_pipeline(df)\n",
    "\n",
    "# Afficher un aperçu du DataFrame final\n",
    "print(\"\\n--- Aperçu du DataFrame 'Parfait' ---\")\n",
    "print(df_cleaned.info())\n",
    "print(\"\\n\")\n",
    "with pd.option_context('display.max_colwidth', 80):\n",
    "    print(df_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359625d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du modèle Spacy pour la lemmatisation...\n",
      "Application de la lemmatisation sur le corpus...\n",
      "\n",
      "--- DÉBUT DU BENCHMARK ---\n",
      "\n",
      "================================================================================\n",
      "ÉVALUATION DU MODÈLE : Qwen/Qwen3-Embedding-0.6B\n",
      "================================================================================\n",
      "\n",
      "--- Test avec min_topic_size = 15 ---\n",
      "Résultats qualitatifs (Top 5 des thèmes) :\n",
      "  Thème 0: ['agent', 'ai agent', 'agent ai', 'multi agent', 'ai', 'multi', 'autonomous', 'framework', 'agentic', 'autonomous agent']\n",
      "  Thème 1: ['chatgpt', 'gpt', 'gpt gpt', 'openai', 'chat', 'chatbot', 'api', 'chatgpt chatgpt', 'free', 'bing']\n",
      "  Thème 2: ['mcp', 'mcp server', 'server', 'mcp mcp', 'protocol', 'context protocol', 'context', 'protocol mcp', 'mcp client', 'claude']\n",
      "  Thème 3: ['inference', 'llama', 'llm', 'serve', 'lora', 'llm inference', 'fine', 'model', 'finetune', 'language model']\n",
      "  Thème 4: ['code', 'copilot', 'vscode', 'plugin', 'github', 'completion', 'developer', 'review', 'extension', 'ide']\n",
      "Résultats : 88 thèmes, 35.28% de bruit, Cohérence C_v: 0.7023, Temps: 102.91s\n",
      "\n",
      "--- Test avec min_topic_size = 12 ---\n",
      "Résultats qualitatifs (Top 5 des thèmes) :\n",
      "  Thème 0: ['agent', 'ai agent', 'agent ai', 'multi agent', 'ai', 'multi', 'framework', 'autonomous', 'agentic', 'autonomous agent']\n",
      "  Thème 1: ['rag', 'vector', 'retrieval', 'search', 'augment generation', 'augment', 'retrieval augment', 'database', 'vector database', 'generation']\n",
      "  Thème 2: ['chatgpt', 'gpt', 'gpt gpt', 'openai', 'chat', 'chatbot', 'api', 'chatgpt chatgpt', 'free', 'turbo']\n",
      "  Thème 3: ['inference', 'llama', 'serve', 'llm inference', 'llm', 'lora', 'fine', 'llm llm', 'finetune', 'model']\n",
      "  Thème 4: ['mcp', 'mcp server', 'server', 'mcp mcp', 'protocol', 'context protocol', 'context', 'protocol mcp', 'claude', 'mcp client']\n",
      "Résultats : 100 thèmes, 31.71% de bruit, Cohérence C_v: 0.6888, Temps: 78.01s\n",
      "\n",
      "--- Test avec min_topic_size = 10 ---\n",
      "Résultats qualitatifs (Top 5 des thèmes) :\n",
      "  Thème 0: ['agent', 'agent ai', 'ai agent', 'multi agent', 'multi', 'ai', 'framework', 'autonomous', 'autonomous agent', 'agentic']\n",
      "  Thème 1: ['chatgpt', 'gpt', 'gpt gpt', 'chat', 'openai', 'chatbot', 'chatgpt chatgpt', 'api', 'free', 'chatbot chatgpt']\n",
      "  Thème 2: ['mcp', 'mcp server', 'server', 'mcp mcp', 'protocol', 'context protocol', 'context', 'protocol mcp', 'claude', 'mcp client']\n",
      "  Thème 3: ['security', 'cybersecurity', 'hack', 'prompt', 'tool', 'team', 'testing', 'scanner', 'ethical', 'analysis']\n",
      "  Thème 4: ['pytorch', 'deep', 'tutorial', 'neural', 'neural network', 'tensorflow', 'deep learn', 'network', 'deep learning', 'learn deep']\n",
      "Résultats : 125 thèmes, 37.35% de bruit, Cohérence C_v: 0.6894, Temps: 86.02s\n",
      "\n",
      "--- Test avec min_topic_size = 8 ---\n",
      "Résultats qualitatifs (Top 5 des thèmes) :\n",
      "  Thème 0: ['agent', 'agent ai', 'ai agent', 'multi agent', 'multi', 'framework', 'autonomous', 'ai', 'agentic', 'autonomous agent']\n",
      "  Thème 1: ['rag', 'retrieval', 'augment generation', 'augment', 'retrieval augment', 'generation', 'llm rag', 'generation rag', 'rag rag', 'rag retrieval']\n",
      "  Thème 2: ['chatgpt', 'gpt', 'gpt gpt', 'openai', 'chat', 'chatbot', 'chatgpt chatgpt', 'api', 'free', 'turbo']\n",
      "  Thème 3: ['mcp', 'mcp server', 'server', 'mcp mcp', 'protocol', 'context protocol', 'context', 'protocol mcp', 'claude', 'mcp client']\n",
      "  Thème 4: ['security', 'cybersecurity', 'hack', 'jailbreak', 'prompt', 'tool', 'team', 'llm security', 'testing', 'scanner']\n",
      "Résultats : 159 thèmes, 32.71% de bruit, Cohérence C_v: 0.6585, Temps: 92.66s\n",
      "\n",
      "--- Test avec min_topic_size = 5 ---\n",
      "Résultats qualitatifs (Top 5 des thèmes) :\n",
      "  Thème 0: ['agent', 'multi agent', 'agent ai', 'ai agent', 'multi', 'autonomous', 'autonomous agent', 'framework', 'agent agent', 'agentic']\n",
      "  Thème 1: ['mcp', 'mcp server', 'server', 'mcp mcp', 'protocol', 'context protocol', 'context', 'protocol mcp', 'mcp client', 'client']\n",
      "  Thème 2: ['security', 'cybersecurity', 'hack', 'jailbreak', 'prompt', 'team', 'tool', 'llm security', 'scanner', 'testing']\n",
      "  Thème 3: ['tutorial', 'neural', 'neural network', 'pytorch', 'tensorflow', 'deep', 'network', 'deep learning', 'deep learn', 'learn deep']\n",
      "  Thème 4: ['solana', 'blockchain', 'web3', 'crypto', 'contract', 'ai agent', 'social', 'agent', 'bitcoin', 'trading']\n",
      "Résultats : 241 thèmes, 31.36% de bruit, Cohérence C_v: 0.6149, Temps: 94.49s\n",
      "\n",
      "================================================================================\n",
      "ÉVALUATION DU MODÈLE : sentence-transformers/all-MiniLM-L6-v2\n",
      "================================================================================\n",
      "\n",
      "--- Test avec min_topic_size = 15 ---\n",
      "Résultats qualitatifs (Top 5 des thèmes) :\n",
      "  Thème 0: ['rag', 'retrieval', 'augment', 'retrieval augment', 'augment generation', 'vector', 'generation', 'search', 'langchain', 'rag retrieval']\n",
      "  Thème 1: ['agent', 'ai agent', 'agent ai', 'ai', 'multi agent', 'agentic', 'multi', 'autonomous', 'framework', 'autonomous agent']\n",
      "  Thème 2: ['speech', 'voice', 'audio', 'music', 'text speech', 'text', 'recognition', 'speech text', 'whisper', 'voice assistant']\n",
      "  Thème 3: ['mcp', 'mcp server', 'server', 'mcp mcp', 'protocol', 'context protocol', 'context', 'claude', 'llm mcp', 'model context']\n",
      "  Thème 4: ['gpt', 'chatgpt', 'gpt gpt', 'openai', 'api', 'gpt4', 'chatgpt gpt', 'free', 'gpt openai', 'chatgpt chatgpt']\n",
      "Résultats : 73 thèmes, 39.92% de bruit, Cohérence C_v: 0.7259, Temps: 6.32s\n",
      "\n",
      "--- Test avec min_topic_size = 12 ---\n",
      "Résultats qualitatifs (Top 5 des thèmes) :\n",
      "  Thème 0: ['chatgpt', 'gpt', 'bot', 'gpt gpt', 'openai', 'chatbot', 'chat', 'telegram', 'api', 'chatgpt chatgpt']\n",
      "  Thème 1: ['agent', 'ai agent', 'agent ai', 'ai', 'multi agent', 'agentic', 'multi', 'autonomous', 'framework', 'autonomous agent']\n",
      "  Thème 2: ['mcp', 'mcp server', 'server', 'mcp mcp', 'protocol', 'context protocol', 'context', 'claude', 'protocol mcp', 'llm mcp']\n",
      "  Thème 3: ['llama', 'inference', 'llm', 'llm inference', 'serve', 'large language', 'language model', 'model', 'lora', 'llama2']\n",
      "  Thème 4: ['data', 'science', 'datum', 'data science', 'visualization', 'analysis', 'datum science', 'data analysis', 'analysis data', 'machine learn']\n",
      "Résultats : 91 thèmes, 38.59% de bruit, Cohérence C_v: 0.7278, Temps: 6.64s\n",
      "\n",
      "--- Test avec min_topic_size = 10 ---\n",
      "Résultats qualitatifs (Top 5 des thèmes) :\n",
      "  Thème 0: ['agent', 'ai agent', 'agent ai', 'agentic', 'ai', 'multi agent', 'framework', 'multi', 'agentic ai', 'autonomous']\n",
      "  Thème 1: ['mcp', 'mcp server', 'server', 'mcp mcp', 'protocol', 'context protocol', 'context', 'claude', 'llm mcp', 'model context']\n",
      "  Thème 2: ['chatgpt', 'gpt', 'gpt gpt', 'openai', 'chatgpt gpt', 'free', 'gpt openai', 'gpt4', 'api', 'chatgpt chatgpt']\n",
      "  Thème 3: ['react', 'nextjs', 'typescript', 'tailwindcss', 'nodejs', 'ui', 'javascript', 'tailwind', 'vercel', 'reactjs']\n",
      "  Thème 4: ['voice', 'speech', 'voice assistant', 'assistant', 'text speech', 'tts', 'speech recognition', 'speech text', 'text', 'whisper']\n",
      "Résultats : 113 thèmes, 43.87% de bruit, Cohérence C_v: 0.7127, Temps: 6.36s\n",
      "\n",
      "--- Test avec min_topic_size = 8 ---\n",
      "Résultats qualitatifs (Top 5 des thèmes) :\n",
      "  Thème 0: ['agent', 'ai agent', 'agent ai', 'multi agent', 'agentic', 'ai', 'autonomous', 'framework', 'multi', 'autonomous agent']\n",
      "  Thème 1: ['mcp', 'mcp server', 'server', 'mcp mcp', 'protocol', 'context protocol', 'context', 'claude', 'model context', 'llm mcp']\n",
      "  Thème 2: ['react', 'nextjs', 'typescript', 'tailwindcss', 'nodejs', 'ui', 'javascript', 'gemini', 'tailwind', 'shadcn']\n",
      "  Thème 3: ['bot', 'slack', 'chatbot', 'telegram', 'discord', 'ai chatbot', 'telegram bot', 'chat', 'conversation', 'wechat']\n",
      "  Thème 4: ['voice', 'speech', 'voice assistant', 'assistant', 'speech text', 'text speech', 'speech recognition', 'tts', 'transcription', 'whisper']\n",
      "Résultats : 143 thèmes, 41.83% de bruit, Cohérence C_v: 0.6931, Temps: 6.33s\n",
      "\n",
      "--- Test avec min_topic_size = 5 ---\n",
      "Résultats qualitatifs (Top 5 des thèmes) :\n",
      "  Thème 0: ['mcp', 'mcp server', 'server', 'mcp mcp', 'protocol', 'context protocol', 'context', 'llm mcp', 'model context', 'claude']\n",
      "  Thème 1: ['react', 'nextjs', 'typescript', 'tailwindcss', 'ui', 'nodejs', 'shadcn', 'reactjs', 'tailwind', 'javascript']\n",
      "  Thème 2: ['chatgpt', 'gpt', 'gpt gpt', 'chatgpt gpt', 'openai', 'gpt openai', 'chatgpt chatgpt', 'free', 'gpt4', 'plus']\n",
      "  Thème 3: ['scrape', 'scraper', 'crawler', 'web', 'scraping', 'crawl', 'web scrape', 'web scraping', 'markdown', 'website']\n",
      "  Thème 4: ['data', 'science', 'visualization', 'datum', 'data analysis', 'data science', 'datum science', 'datum visualization', 'analysis data', 'analysis']\n",
      "Résultats : 242 thèmes, 37.95% de bruit, Cohérence C_v: 0.6293, Temps: 6.38s\n",
      "\n",
      "================================================================================\n",
      "ÉVALUATION DU MODÈLE : intfloat/multilingual-e5-large-instruct\n",
      "================================================================================\n",
      "\n",
      "--- Test avec min_topic_size = 15 ---\n",
      "Résultats qualitatifs (Top 5 des thèmes) :\n",
      "  Thème 0: ['rag', 'retrieval', 'augment', 'retrieval augment', 'augment generation', 'vector', 'generation', 'search', 'rag retrieval', 'document']\n",
      "  Thème 1: ['deep', 'tensorflow', 'pytorch', 'deep learn', 'neural', 'neural network', 'network', 'image', 'keras', 'learn']\n",
      "  Thème 2: ['mcp', 'mcp server', 'server', 'mcp mcp', 'protocol', 'context protocol', 'context', 'claude', 'model context', 'llm mcp']\n",
      "  Thème 3: ['nextjs', 'react', 'typescript', 'nodejs', 'ui', 'vercel', 'javascript', 'gemini', 'css', 'vite']\n",
      "  Thème 4: ['chatgpt', 'gpt', 'openai', 'support', 'qwen', 'chat', 'chinese', 'llm', 'bot', 'deepseek']\n",
      "Résultats : 66 thèmes, 42.01% de bruit, Cohérence C_v: 0.7352, Temps: 46.06s\n",
      "\n",
      "--- Test avec min_topic_size = 12 ---\n",
      "Résultats qualitatifs (Top 5 des thèmes) :\n",
      "  Thème 0: ['mcp', 'mcp server', 'server', 'mcp mcp', 'protocol', 'context protocol', 'context', 'claude', 'model context', 'llm mcp']\n",
      "  Thème 1: ['data', 'science', 'data science', 'datum', 'machine', 'machine learn', 'visualization', 'analysis', 'data analysis', 'panda']\n",
      "  Thème 2: ['nextjs', 'react', 'typescript', 'tailwindcss', 'ui', 'vercel', 'nodejs', 'tailwind', 'gemini', 'javascript']\n",
      "  Thème 3: ['chatgpt', 'gpt', 'support', 'wechat', 'deepseek', 'openai', 'chat', 'qwen', 'chinese', 'llm']\n",
      "  Thème 4: ['gpt', 'chatgpt', 'gpt gpt', 'openai', 'free', 'api', 'chatgpt chatgpt', 'bing', 'gpt openai', 'gpt4']\n",
      "Résultats : 89 thèmes, 46.11% de bruit, Cohérence C_v: 0.7230, Temps: 50.59s\n",
      "\n",
      "--- Test avec min_topic_size = 10 ---\n",
      "Résultats qualitatifs (Top 5 des thèmes) :\n",
      "  Thème 0: ['mcp', 'mcp server', 'server', 'mcp mcp', 'protocol', 'context protocol', 'context', 'claude', 'model context', 'llm mcp']\n",
      "  Thème 1: ['nextjs', 'react', 'typescript', 'ui', 'tailwind', 'nodejs', 'vercel', 'javascript', 'gemini', 'vite']\n",
      "  Thème 2: ['data', 'science', 'datum', 'data science', 'visualization', 'analysis', 'data analysis', 'panda', 'analysis data', 'datum science']\n",
      "  Thème 3: ['chatgpt', 'qwen', 'gpt', 'openai', 'chatglm', 'subtitle', 'llm', 'deepseek', 'video', 'translation']\n",
      "  Thème 4: ['gpt', 'chatgpt', 'gpt gpt', 'openai', 'free', 'api', 'chatgpt chatgpt', 'gpt openai', 'gpt4', 'chatbot chatgpt']\n",
      "Résultats : 102 thèmes, 45.64% de bruit, Cohérence C_v: 0.7234, Temps: 54.33s\n",
      "\n",
      "--- Test avec min_topic_size = 8 ---\n",
      "Résultats qualitatifs (Top 5 des thèmes) :\n",
      "  Thème 0: ['mcp', 'mcp server', 'server', 'mcp mcp', 'protocol', 'context protocol', 'context', 'claude', 'model context', 'llm mcp']\n",
      "  Thème 1: ['nextjs', 'react', 'typescript', 'nodejs', 'vercel', 'ui', 'vite', 'javascript', 'css', 'reactjs']\n",
      "  Thème 2: ['gpt', 'chatgpt', 'gpt gpt', 'openai', 'free', 'api', 'gpt openai', 'chatgpt chatgpt', 'openai api', 'gpt4']\n",
      "  Thème 3: ['retrieval', 'augment', 'retrieval augment', 'augment generation', 'rag', 'generation', 'generation rag', 'rag retrieval', 'llm rag', 'evaluation']\n",
      "  Thème 4: ['attention', 'transformer', 'attention mechanism', 'mechanism', 'intelligence attention', 'implementation', 'mechanism deep', 'pytorch', 'pytorch artificial', 'pytorch transformer']\n",
      "Résultats : 123 thèmes, 41.50% de bruit, Cohérence C_v: 0.6985, Temps: 54.71s\n",
      "\n",
      "--- Test avec min_topic_size = 5 ---\n",
      "Résultats qualitatifs (Top 5 des thèmes) :\n",
      "  Thème 0: ['mcp', 'mcp server', 'server', 'mcp mcp', 'protocol', 'context protocol', 'context', 'llm mcp', 'claude', 'client']\n",
      "  Thème 1: ['attention', 'transformer', 'attention mechanism', 'mechanism', 'intelligence attention', 'implementation', 'mechanism deep', 'pytorch', 'pytorch artificial', 'transformer transformer']\n",
      "  Thème 2: ['qwen', 'chatgpt', 'chatglm', 'deepseek', 'openai', 'gpt', 'spring', 'llm', 'http', 'gateway']\n",
      "  Thème 3: ['dataset', 'source code', 'code dataset', 'lang', 'category', 'programming language', 'contain', 'source', 'programming', 'project']\n",
      "  Thème 4: ['security', 'cybersecurity', 'hack', 'llm security', 'tool', 'jailbreak', 'exploit', 'scanner', 'assessment', 'team']\n",
      "Résultats : 235 thèmes, 38.63% de bruit, Cohérence C_v: 0.6247, Temps: 56.15s\n",
      "\n",
      "================================================================================\n",
      "ÉVALUATION DU MODÈLE : sentence-transformers/all-mpnet-base-v2\n",
      "================================================================================\n",
      "\n",
      "--- Test avec min_topic_size = 15 ---\n",
      "Résultats qualitatifs (Top 5 des thèmes) :\n",
      "  Thème 0: ['agent', 'ai agent', 'ai', 'agent ai', 'agentic', 'multi agent', 'workflow', 'multi', 'autonomous', 'framework']\n",
      "  Thème 1: ['rag', 'retrieval', 'augment', 'retrieval augment', 'augment generation', 'search', 'vector', 'generation', 'rag retrieval', 'database']\n",
      "  Thème 2: ['speech', 'voice', 'audio', 'music', 'speech recognition', 'text speech', 'text', 'whisper', 'recognition', 'tts']\n",
      "  Thème 3: ['chatgpt', 'gpt', 'gpt gpt', 'openai', 'terminal', 'gpt openai', 'chatgpt gpt', 'api', 'prompt', 'free']\n",
      "  Thème 4: ['mcp', 'mcp server', 'server', 'mcp mcp', 'protocol', 'context protocol', 'claude', 'context', 'protocol mcp', 'claude code']\n",
      "Résultats : 77 thèmes, 31.58% de bruit, Cohérence C_v: 0.7246, Temps: 21.49s\n",
      "\n",
      "--- Test avec min_topic_size = 12 ---\n",
      "Résultats qualitatifs (Top 5 des thèmes) :\n",
      "  Thème 0: ['rag', 'retrieval', 'augment', 'retrieval augment', 'augment generation', 'search', 'vector', 'generation', 'rag retrieval', 'database']\n",
      "  Thème 1: ['agent', 'ai agent', 'agent ai', 'agentic', 'multi agent', 'ai', 'multi', 'agent agent', 'autonomous', 'agentic ai']\n",
      "  Thème 2: ['speech', 'voice', 'audio', 'music', 'speech recognition', 'text speech', 'text', 'whisper', 'recognition', 'tts']\n",
      "  Thème 3: ['chatgpt', 'gpt', 'gpt gpt', 'openai', 'terminal', 'gpt openai', 'free', 'chatgpt gpt', 'chatgpt chatgpt', 'api']\n",
      "  Thème 4: ['mcp', 'mcp server', 'server', 'mcp mcp', 'protocol', 'context protocol', 'context', 'protocol mcp', 'claude', 'llm mcp']\n",
      "Résultats : 93 thèmes, 35.06% de bruit, Cohérence C_v: 0.7148, Temps: 19.54s\n",
      "\n",
      "--- Test avec min_topic_size = 10 ---\n",
      "Résultats qualitatifs (Top 5 des thèmes) :\n",
      "  Thème 0: ['agent', 'ai agent', 'agent ai', 'agentic', 'multi agent', 'ai', 'multi', 'agent agent', 'agentic ai', 'framework']\n",
      "  Thème 1: ['speech', 'voice', 'audio', 'music', 'speech recognition', 'text speech', 'whisper', 'tts', 'recognition', 'text']\n",
      "  Thème 2: ['chatgpt', 'gpt', 'gpt gpt', 'openai', 'gpt openai', 'terminal', 'chatgpt gpt', 'free', 'chatgpt chatgpt', 'api']\n",
      "  Thème 3: ['mcp', 'mcp server', 'server', 'mcp mcp', 'protocol', 'context protocol', 'context', 'protocol mcp', 'claude', 'llm mcp']\n",
      "  Thème 4: ['retrieval', 'retrieval augment', 'augment', 'augment generation', 'rag', 'generation', 'rag retrieval', 'generation rag', 'evaluation', 'llm rag']\n",
      "Résultats : 114 thèmes, 37.63% de bruit, Cohérence C_v: 0.7101, Temps: 19.49s\n",
      "\n",
      "--- Test avec min_topic_size = 8 ---\n",
      "Résultats qualitatifs (Top 5 des thèmes) :\n",
      "  Thème 0: ['agent', 'ai agent', 'agent ai', 'agentic', 'multi agent', 'ai', 'multi', 'workflow', 'agentic ai', 'agent agent']\n",
      "  Thème 1: ['chatgpt', 'gpt', 'gpt gpt', 'openai', 'gpt openai', 'terminal', 'free', 'chatgpt gpt', 'chatgpt chatgpt', 'prompt']\n",
      "  Thème 2: ['mcp', 'mcp server', 'server', 'mcp mcp', 'protocol', 'context protocol', 'context', 'protocol mcp', 'llm mcp', 'claude']\n",
      "  Thème 3: ['pytorch', 'deep', 'tensorflow', 'neural', 'neural network', 'network', 'deep learn', 'learn pytorch', 'learn', 'tutorial']\n",
      "  Thème 4: ['dataset', 'source code', 'code dataset', 'lang', 'category', 'programming language', 'source', 'contain', 'programming', 'code']\n",
      "Résultats : 143 thèmes, 36.49% de bruit, Cohérence C_v: 0.6736, Temps: 19.47s\n",
      "\n",
      "--- Test avec min_topic_size = 5 ---\n",
      "Résultats qualitatifs (Top 5 des thèmes) :\n",
      "  Thème 0: ['chatgpt', 'gpt', 'gpt gpt', 'openai', 'gpt openai', 'terminal', 'chatgpt gpt', 'free', 'chatgpt chatgpt', 'gpt4']\n",
      "  Thème 1: ['mcp', 'mcp server', 'server', 'mcp mcp', 'protocol', 'context protocol', 'context', 'protocol mcp', 'llm mcp', 'model context']\n",
      "  Thème 2: ['dataset', 'source code', 'code dataset', 'lang', 'category', 'programming language', 'contain', 'source', 'programming', 'project']\n",
      "  Thème 3: ['augment', 'rag', 'augment generation', 'retrieval augment', 'retrieval', 'rag retrieval', 'generation rag', 'evaluation', 'generation', 'llm rag']\n",
      "  Thème 4: ['transformer', 'attention', 'attention mechanism', 'mechanism', 'intelligence attention', 'mechanism deep', 'pytorch transformer', 'implementation', 'transformer model', 'pytorch artificial']\n",
      "Résultats : 235 thèmes, 36.48% de bruit, Cohérence C_v: 0.6210, Temps: 19.43s\n",
      "\n",
      "================================================================================\n",
      "ÉVALUATION DU MODÈLE : BAAI/bge-large-en-v1.5\n",
      "================================================================================\n",
      "\n",
      "--- Test avec min_topic_size = 15 ---\n",
      "Résultats qualitatifs (Top 5 des thèmes) :\n",
      "  Thème 0: ['agent', 'ai agent', 'ai', 'agent ai', 'agentic', 'multi agent', 'multi', 'langgraph', 'llm', 'autonomous']\n",
      "  Thème 1: ['learn', 'machine', 'machine learn', 'data', 'science', 'deep', 'data science', 'deep learn', 'datum', 'tensorflow']\n",
      "  Thème 2: ['rag', 'retrieval', 'augment', 'retrieval augment', 'augment generation', 'vector', 'generation', 'search', 'rag retrieval', 'database']\n",
      "  Thème 3: ['gpt', 'chatgpt', 'gpt gpt', 'openai', 'api', 'chat', 'bot', 'prompt', 'chatgpt chatgpt', 'chatbot']\n",
      "  Thème 4: ['mcp', 'server', 'mcp server', 'mcp mcp', 'protocol', 'context protocol', 'context', 'claude', 'model context', 'llm mcp']\n",
      "Résultats : 58 thèmes, 36.92% de bruit, Cohérence C_v: 0.7509, Temps: 52.55s\n",
      "\n",
      "--- Test avec min_topic_size = 12 ---\n",
      "Résultats qualitatifs (Top 5 des thèmes) :\n",
      "  Thème 0: ['agent', 'ai agent', 'agentic', 'ai', 'agent ai', 'multi agent', 'langgraph', 'multi', 'autonomous', 'agentic ai']\n",
      "  Thème 1: ['chatgpt', 'gpt', 'gpt gpt', 'openai', 'api', 'chat', 'chatgpt chatgpt', 'bot', 'gpt openai', 'chatgpt gpt']\n",
      "  Thème 2: ['mcp', 'mcp server', 'server', 'mcp mcp', 'protocol', 'context protocol', 'context', 'claude', 'llm mcp', 'client']\n",
      "  Thème 3: ['retrieval', 'retrieval augment', 'augment', 'augment generation', 'rag', 'generation', 'rag retrieval', 'generation rag', 'graph', 'knowledge']\n",
      "  Thème 4: ['rag', 'chatbot', 'rag chatbot', 'pdf', 'langchain', 'streamlit', 'faiss', 'document', 'answer', 'question']\n",
      "Résultats : 81 thèmes, 43.07% de bruit, Cohérence C_v: 0.7361, Temps: 57.87s\n",
      "\n",
      "--- Test avec min_topic_size = 10 ---\n",
      "Résultats qualitatifs (Top 5 des thèmes) :\n",
      "  Thème 0: ['agent', 'ai agent', 'agentic', 'agent ai', 'ai', 'multi agent', 'multi', 'autonomous', 'langgraph', 'agentic ai']\n",
      "  Thème 1: ['mcp', 'mcp server', 'server', 'mcp mcp', 'protocol', 'context protocol', 'context', 'claude', 'model context', 'llm mcp']\n",
      "  Thème 2: ['spark', 'ml', 'distribute', 'mlop', 'machine', 'machine learn', 'tensorflow', 'learn', 'kubernete', 'automl']\n",
      "  Thème 3: ['object', 'object detection', 'detection', 'pose', 'hand', 'computer vision', 'track', 'pose estimation', 'vision', 'computer']\n",
      "  Thème 4: ['rag', 'chatbot', 'rag chatbot', 'langchain', 'streamlit', 'pdf', 'rag rag', 'faiss', 'document', 'chromadb']\n",
      "Résultats : 96 thèmes, 42.91% de bruit, Cohérence C_v: 0.7296, Temps: 58.67s\n",
      "\n",
      "--- Test avec min_topic_size = 8 ---\n",
      "Résultats qualitatifs (Top 5 des thèmes) :\n",
      "  Thème 0: ['agent', 'agentic', 'ai agent', 'agent ai', 'ai', 'multi agent', 'langgraph', 'multi', 'autonomous', 'agentic ai']\n",
      "  Thème 1: ['mcp', 'mcp server', 'server', 'mcp mcp', 'protocol', 'context protocol', 'context', 'claude', 'llm mcp', 'mcp client']\n",
      "  Thème 2: ['game', 'reinforcement', 'algorithm', 'reinforcement learn', 'optimization', 'genetic', 'genetic algorithm', 'reinforcement learning', 'deep reinforcement', 'play']\n",
      "  Thème 3: ['rag', 'chatbot', 'rag chatbot', 'pdf', 'langchain', 'rag rag', 'faiss', 'document', 'streamlit', 'answer']\n",
      "  Thème 4: ['data', 'datum', 'science', 'visualization', 'data science', 'datum science', 'analysis', 'data analysis', 'analysis data', 'datum visualization']\n",
      "Résultats : 129 thèmes, 43.30% de bruit, Cohérence C_v: 0.6863, Temps: 59.57s\n",
      "\n",
      "--- Test avec min_topic_size = 5 ---\n",
      "Résultats qualitatifs (Top 5 des thèmes) :\n",
      "  Thème 0: ['mcp', 'mcp server', 'server', 'mcp mcp', 'protocol', 'context protocol', 'context', 'model context', 'claude', 'llm mcp']\n",
      "  Thème 1: ['dataset', 'source code', 'code dataset', 'lang', 'category', 'programming language', 'contain', 'source', 'programming', 'project']\n",
      "  Thème 2: ['retrieval', 'retrieval augment', 'augment', 'augment generation', 'rag retrieval', 'generation', 'rag', 'generation rag', 'chunk', 'llm rag']\n",
      "  Thème 3: ['awesome', 'list', 'awesome list', 'curate list', 'curate', 'list awesome', 'awesome awesome', 'resource', 'intelligence awesome', 'ai tool']\n",
      "  Thème 4: ['blockchain', 'web3', 'trading', 'ai agent', 'social', 'agent', 'evm', 'crypto', 'agent build', 'social medium']\n",
      "Résultats : 224 thèmes, 40.87% de bruit, Cohérence C_v: 0.6311, Temps: 60.42s\n",
      "\n",
      "\n",
      "================================================================================\n",
      "SYNTHÈSE FINALE DU BENCHMARK\n",
      "================================================================================\n",
      "                                  model  min_topic_size  Temps (s)  Nb Thèmes  % Bruit  Cohérence (C_v)\n",
      "                 BAAI/bge-large-en-v1.5               5      60.42        224    40.87           0.6311\n",
      "                 BAAI/bge-large-en-v1.5               8      59.57        129    43.30           0.6863\n",
      "                 BAAI/bge-large-en-v1.5              10      58.67         96    42.91           0.7296\n",
      "                 BAAI/bge-large-en-v1.5              12      57.87         81    43.07           0.7361\n",
      "                 BAAI/bge-large-en-v1.5              15      52.55         58    36.92           0.7509\n",
      "              Qwen/Qwen3-Embedding-0.6B               5      94.49        241    31.36           0.6149\n",
      "              Qwen/Qwen3-Embedding-0.6B               8      92.66        159    32.71           0.6585\n",
      "              Qwen/Qwen3-Embedding-0.6B              10      86.02        125    37.35           0.6894\n",
      "              Qwen/Qwen3-Embedding-0.6B              12      78.01        100    31.71           0.6888\n",
      "              Qwen/Qwen3-Embedding-0.6B              15     102.91         88    35.28           0.7023\n",
      "intfloat/multilingual-e5-large-instruct               5      56.15        235    38.63           0.6247\n",
      "intfloat/multilingual-e5-large-instruct               8      54.71        123    41.50           0.6985\n",
      "intfloat/multilingual-e5-large-instruct              10      54.33        102    45.64           0.7234\n",
      "intfloat/multilingual-e5-large-instruct              12      50.59         89    46.11           0.7230\n",
      "intfloat/multilingual-e5-large-instruct              15      46.06         66    42.01           0.7352\n",
      " sentence-transformers/all-MiniLM-L6-v2               5       6.38        242    37.95           0.6293\n",
      " sentence-transformers/all-MiniLM-L6-v2               8       6.33        143    41.83           0.6931\n",
      " sentence-transformers/all-MiniLM-L6-v2              10       6.36        113    43.87           0.7127\n",
      " sentence-transformers/all-MiniLM-L6-v2              12       6.64         91    38.59           0.7278\n",
      " sentence-transformers/all-MiniLM-L6-v2              15       6.32         73    39.92           0.7259\n",
      "sentence-transformers/all-mpnet-base-v2               5      19.43        235    36.48           0.6210\n",
      "sentence-transformers/all-mpnet-base-v2               8      19.47        143    36.49           0.6736\n",
      "sentence-transformers/all-mpnet-base-v2              10      19.49        114    37.63           0.7101\n",
      "sentence-transformers/all-mpnet-base-v2              12      19.54         93    35.06           0.7148\n",
      "sentence-transformers/all-mpnet-base-v2              15      21.49         77    31.58           0.7246\n",
      "\n",
      "--- FIN DU BENCHMARK ---\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Définition des Modèles à Bencher ---\n",
    "\n",
    "# Sélection des modèles conformément au rapport E2\n",
    "models_to_benchmark = [\n",
    " \"Qwen/Qwen3-Embedding-0.6B\",\n",
    " \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    " \"intfloat/multilingual-e5-large-instruct\",\n",
    " \"sentence-transformers/all-mpnet-base-v2\",\n",
    " \"BAAI/bge-large-en-v1.5\"\n",
    "]\n",
    "\n",
    "\n",
    "benchmark_results = []\n",
    "corpus = df_cleaned['cleaned_text'].tolist()\n",
    "# Tokenizer le corpus pour le calcul de la cohérence\n",
    "tokenized_corpus = [doc.split() for doc in corpus]\n",
    "\n",
    "# AMÉLIORATION 1 : Lemmatisation\n",
    "print(\"Chargement du modèle Spacy pour la lemmatisation...\")\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "\n",
    "def lemmatize(text):\n",
    "    doc = nlp(text)\n",
    "    return \" \".join([token.lemma_ for token in doc])\n",
    "\n",
    "print(\"Application de la lemmatisation sur le corpus...\")\n",
    "df_cleaned['lemmatized_text'] = df_cleaned['cleaned_text'].apply(lemmatize)\n",
    "corpus = df_cleaned['lemmatized_text'].tolist()\n",
    "tokenized_corpus = [doc.split() for doc in corpus]\n",
    "\n",
    "\n",
    "# AMÉLIORATION 2 : Test de différentes granularités de thèmes\n",
    "min_topic_sizes_to_test = [15, 12, 10, 8, 5]\n",
    "\n",
    "# AMÉLIORATION 3 : Vectoriseur personnalisé\n",
    "vectorizer_model = CountVectorizer(ngram_range=(1, 2), min_df=5, stop_words=\"english\")\n",
    "\n",
    "benchmark_results = []\n",
    "\n",
    "# --- 3. Exécution du Benchmark ---\n",
    "print(\"\\n--- DÉBUT DU BENCHMARK ---\")\n",
    "\n",
    "for model in models_to_benchmark:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ÉVALUATION DU MODÈLE : {model}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    embedding_model = SentenceTransformer(model)\n",
    "\n",
    "    for min_size in min_topic_sizes_to_test:\n",
    "        print(f\"\\n--- Test avec min_topic_size = {min_size} ---\")\n",
    "        \n",
    "        topic_model = BERTopic(\n",
    "            embedding_model=embedding_model,\n",
    "            min_topic_size=min_size,\n",
    "            vectorizer_model=vectorizer_model, # Utilisation du vectoriseur personnalisé\n",
    "            verbose=False # Mis à False pour alléger la sortie\n",
    "        )\n",
    "\n",
    "        start_time = time.time()\n",
    "        topics, _ = topic_model.fit_transform(corpus)\n",
    "        duration = time.time() - start_time\n",
    "\n",
    "        topic_info = topic_model.get_topic_info()\n",
    "        num_topics_found = len(topic_info) - 1\n",
    "        num_outliers = topic_info.loc[topic_info['Topic'] == -1, 'Count'].iloc[0] if -1 in topic_info['Topic'].values else 0\n",
    "        noise_percentage = (num_outliers / len(corpus)) * 100\n",
    "\n",
    "        coherence_score = 0.0\n",
    "        if num_topics_found > 0:\n",
    "            dictionary = Dictionary(tokenized_corpus)\n",
    "            bow_corpus = [dictionary.doc2bow(doc) for doc in tokenized_corpus]\n",
    "            topic_words = [[words[0] for words in topic_model.get_topic(topic_id)] for topic_id in range(num_topics_found)]\n",
    "            coherence_model = CoherenceModel(topics=topic_words, texts=tokenized_corpus, corpus=bow_corpus, dictionary=dictionary, coherence='c_v')\n",
    "            coherence_score = coherence_model.get_coherence()\n",
    "\n",
    "        print(\"Résultats qualitatifs (Top 5 des thèmes) :\")\n",
    "        for topic_id in range(min(5, num_topics_found)):\n",
    "            keywords = topic_model.get_topic(topic_id)\n",
    "            if keywords:\n",
    "                print(f\"  Thème {topic_id}: {[word for word, score in keywords]}\")\n",
    "\n",
    "        print(f\"Résultats : {num_topics_found} thèmes, {noise_percentage:.2f}% de bruit, Cohérence C_v: {coherence_score:.4f}, Temps: {duration:.2f}s\")\n",
    "\n",
    "        benchmark_results.append({\n",
    "            \"model\": model,\n",
    "            \"min_topic_size\": min_size,\n",
    "            \"Temps (s)\": round(duration, 2),\n",
    "            \"Nb Thèmes\": num_topics_found,\n",
    "            \"% Bruit\": round(noise_percentage, 2),\n",
    "            \"Cohérence (C_v)\": round(coherence_score, 4)\n",
    "        })\n",
    "\n",
    "# --- 4. Analyse des Résultats ---\n",
    "print(f\"\\n\\n{'='*80}\")\n",
    "print(\"SYNTHÈSE FINALE DU BENCHMARK\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "summary_df = pd.DataFrame(benchmark_results)\n",
    "# Trier pour une meilleure lisibilité\n",
    "summary_df.sort_values(by=[\"model\", \"min_topic_size\"], inplace=True)\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n--- FIN DU BENCHMARK ---\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
